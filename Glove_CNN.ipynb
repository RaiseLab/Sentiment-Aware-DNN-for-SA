{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Glove_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-Z15bFfZ3DO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afe76e83-7fc9-4ef1-87bd-fa5a56767fec"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9ARMMPuaDHf"
      },
      "source": [
        "path = \"/content/drive/MyDrive/JK_Research/Sentiment-Analysis-using-BERT-master/Test/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VtNT7j3O2Ix"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "from tensorflow.keras.optimizers import RMSprop,Adam\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.utils import shuffle\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HsOkCtwaEuf"
      },
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/JK_Research/Sentiment-Analysis-using-BERT-master/BERT-base/train_set.csv\")\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/JK_Research/Sentiment-Analysis-using-BERT-master/BERT-base/test_set.csv')\n",
        "# df = pd.concat([df,df_test])\n",
        "df = df.dropna()\n",
        "# print(df)\n",
        "# print(df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPFb7__TaFhT"
      },
      "source": [
        "data = df.review.astype(str)\n",
        "#data = np.array(data)\n",
        "data = data.to_list()\n",
        "label = df.label.tolist()\n",
        "data_test = df_test.review.astype(str)\n",
        "#data_test = np.array(data_test)\n",
        "data_test = data_test.to_list()\n",
        "label_test = df_test.label.to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH1GHTMUO7bC"
      },
      "source": [
        "import pickle\n",
        "with open('/content/drive/MyDrive/JK_Research/Sentiment-Analysis-using-BERT-master/Test/glove.model', 'rb') as pickle_file:\n",
        "    embeddings_index = pickle.load(pickle_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIKSALJTO-CJ"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "tokenizer  = Tokenizer(num_words = 10000)\n",
        "tokenizer.fit_on_texts(data)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print(\"unique words : {}\".format(len(word_index)))\n",
        "\n",
        "sequences =  tokenizer.texts_to_sequences(data)\n",
        "sequences_test =  tokenizer.texts_to_sequences(data_test)\n",
        "\n",
        "maxlen = 300\n",
        "data1 = pad_sequences(sequences, maxlen=maxlen)\n",
        "test1 = pad_sequences(sequences_test, maxlen=maxlen)\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "label = le.fit_transform(label)\n",
        "labels = label.reshape(-1,1)\n",
        "labels_test = le.fit_transform(label_test)\n",
        "labels_test = labels_test.reshape(-1,1)\n",
        "labels = to_categorical(np.asarray(label))\n",
        "labels_test = to_categorical(np.asarray(label_test))\n",
        "print(data1.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "x_train,x_val,y_train,y_val = train_test_split(data1,label,test_size=0.30, random_state=48)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sd6_QERPBqt"
      },
      "source": [
        "def convert_to_sequences(texts):\n",
        "  sequences =  tokenizer.texts_to_sequences(texts)\n",
        "  return pad_sequences(sequences, maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpNzAcD0PDnB"
      },
      "source": [
        "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
        "print(embedding_matrix.shape)\n",
        "for word, i in word_index.items():\n",
        "    # print(word)\n",
        "    try:\n",
        "        embedding_vector = embeddings_index['word_vectors'][embeddings_index['dictionary'][word]]\n",
        "    except KeyError:\n",
        "        embedding_vector = None\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCGE2Ts-Pq-P"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Dense, Input, Flatten, SpatialDropout1D\n",
        "from tensorflow.keras.layers import Conv1D,MaxPool1D, Embedding, Concatenate, Dropout,GlobalMaxPool1D,Lambda\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vC5Nc4qCPF_Z"
      },
      "source": [
        "embedding_layer = Embedding(len(word_index) + 1,\n",
        "                            300,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=maxlen,\n",
        "                            trainable=True)\n",
        "\n",
        "sequence_input = Input(shape=(maxlen,), dtype='int32')\n",
        "embedded_sequences = embedding_layer(sequence_input)\n",
        "bert_out = SpatialDropout1D(0.5)(embedded_sequences)\n",
        "filter_lengths = [3, 4, 5]\n",
        "conv_layers = []\n",
        "for filter_length in filter_lengths:\n",
        "    conv_layer = Conv1D(filters=100, kernel_size=filter_length, padding='valid',\n",
        "                        strides=1, activation='relu')(bert_out)\n",
        "    maxpooling = MaxPool1D(pool_size=128 - filter_length + 1)(conv_layer)\n",
        "    flatten = Flatten()(maxpooling)\n",
        "    conv_layers.append(flatten)\n",
        "    \n",
        "sentence_embed = Concatenate()(conv_layers)\n",
        "\n",
        "dense_layer = Dense(128, activation='relu')(sentence_embed)\n",
        "preds = Dense(1, activation='sigmoid')(dense_layer)\n",
        "model = Model(sequence_input, preds)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.0003),\n",
        "              metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQWHgBB9PH4Y"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint('/content/drive/MyDrive/JK_Research/Sentiment-Analysis-using-BERT-master/Test/model.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
        "callbacks_list = [checkpoint]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train,y_train,epochs=10,batch_size=128,verbose = 1,validation_data=[x_val,y_val],callbacks=callbacks_list)"
      ],
      "metadata": {
        "id": "is6o7YMOsTP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1eTvEGZPL_Z"
      },
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW3wtJJqPNcT"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s9TCiFDPQCA"
      },
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/JK_Research/Sentiment-Analysis-using-BERT-master/Test/model.h5')\n",
        "# accr = model.evaluate(test1,label_test)\n",
        "# print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmDj4XvXnSne"
      },
      "source": [
        "from sklearn import metrics\n",
        "acc = model.predict(test1)\n",
        "accr = np.round(acc)\n",
        "print(metrics.f1_score(label_test, accr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha8dYgqvDcmL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}